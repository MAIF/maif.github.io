[
  {
    "text": "Mélusine, un retour d’expérience MAIF !",
    "author_id": "Tiphaine Fabre",
    "created_at": "2021-11-30 19:08:06",
    "id": "https://medium.com/p/1ce5cd50802b",
    "author_username": "Tiphaine Fabre",
    "author_name": "Tiphaine Fabre",
    "thumbnail": "https://cdn-images-1.medium.com/max/605/1*FgzebakIvFYSqdKIWP9eug.png",
    "description": "\n<h3>Mélusine, un retour d’expérience MAIF !</h3>\n<p>Cela fait maintenant presque trois ans que nous nous sommes lancés dans l’optimisation du traitement des flux mails entrants à MAIF. Nous avions à cette occasion libéré en Open Source la <a href=\"https://github.com/MAIF/melusine\">librairie Mélusine</a> permettant la qualification des emails entrants grâce à des techniques avancées de traitement du langage, développée avec notre partenaire Quantmetry.</p>\n<p>Il était donc temps pour nous de revenir sur le chemin parcouru mais également vous partager nos ambitions pour les années à venir !</p>\n<h3>Pourquoi avoir créé Mélusine ? C’était quoi le besoin ?</h3>\n<p>Commençons par le commencement ! MAIF, c’est plus de 3 millions de sociétaires et plus de 15000 mails reçus <strong>par jour. </strong>C’est donc beaucoup de mails à traiter par nos gestionnaires et conseillers. Il nous fallait trouver une solution pour<strong> soulager leur charge de travail et réduire le délai de réponse à nos sociétaires.</strong></p>\n<h4>Le routage des mails</h4>\n<p>Une des premières problématiques rencontrées était <strong>le routage des mails</strong>. Et par routage, on entend distribuer le mail à l’entité compétente pour le traiter.</p>\n<p>MAIF utilise des <strong>boites à lettres génériques</strong> pour les différents métiers de l’assurance : la gestion d’un sinistre, sa déclaration ou encore la gestion des contrats. Dans ces métiers, se détaillent de nombreuses spécialités comme, par exemple, la gestion de contrats automobiles, navigation ou habitation. Ces spécialités nécessitent une expertise de la part de nos utilisateurs. Un conseiller expert en contrat automobile est rarement expert en contrat navigation. Nous avions donc besoin de comprendre le contenu du mail pour l’attribuer au conseiller expert compétent et limiter les rebonds qui peuvent rallonger les délais de réponse.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/605/1*FgzebakIvFYSqdKIWP9eug.png\"></figure><p>Aujourd’hui, dans le domaine « Contrats », Mélusine permet un routage vers le bon expert dans plus de 84% des cas. On a ainsi pu voir <strong>une réduction du délai de réponse au sociétaire de 40%</strong> dans certains domaines d’expertise.</p>\n<h3>Une évolution constante du périmètre et des améliorations de l’existant.</h3>\n<p>A l’initiale de ce projet, en 2018, nous avions préféré cibler les mails du domaine « Contrats » pour faire la preuve de nos développements et montrer la valeur que pouvait apporter l’Intelligence Artificielle dans la gestion des flux entrants mails. Grâce à cette première expérience positive sur un périmètre restreint, nous avons suscité l’intérêt des utilisateurs et avons rapidement entamé des travaux sur les mails du domaine « Sinistres ». Fin 2019, nous faisions notre première mise en production sur ce domaine.</p>\n<p>Depuis, nous n’arrêtons pas d’étendre le périmètre de Mélusine dans le traitement de flux : de nombreux cas d’usages, traitements de flux autres que mails (ex : commentaires d’experts), améliorations des cas d’usages existants.</p>\n<h4>Mélusine, ce n’est pas que le routage !</h4>\n<p>Grâce aux technologies utilisées pour l’analyse du langage, nous avons pu enclencher de nombreux types de traitements : de la priorisation, de la clôture de mails, de la réponse automatique, etc…</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/605/1*6BLkCkJTGZYJ8NRL6CU46Q.png\"></figure><p>En effet, au-delà du routage, un mail contient de nombreuses informations à mettre en valeur ou utiliser pour faciliter le quotidien de nos utilisateurs. Les différentes briques de la librairie Mélusine Open source peuvent alors être réutilisées à volonté.</p>\n<p>Une fois la segmentation du mail réalisée (identification des signatures, remerciements, corps du mail etc…), on peut cibler la partie du mail qui nous intéresse et entraîner un modèle d’intelligence artificielle (réseau de neurone) pour réaliser le traitement souhaité.</p>\n<h4>Des réseaux de neurones pour tous les cas d’usages ?</h4>\n<p>Dans la majorité de nos cas d’usages, on répond à une question « simple » qui nécessite une réponse binaire (oui, ou: non?). Pour vous donner un exemple concret, aujourd’hui en production, on veut savoir si le message nécessite une action ou non du gestionnaire/conseiller. Le modèle devra alors répondre « Information » ou « Action ».</p>\n<p>On peut alors aborder la problématique par des méthodes de classification supervisée, i.e. notre modèle s’entrainera avec des données pour lesquelles il connait déjà les réponses. Cela nécessite, bien sûr, en amont, la préparation d’un jeu de données.</p>\n<p>Nous nous appuyons systématiquement sur les métiers pour réaliser cette préparation car seuls eux peuvent retranscrire les pratiques du quotidien. Selon la complexité du cas d’usage, le volume de messages à annoter nécessaire varie d’une centaine à quelques milliers par catégorie à prédire.</p>\n<p>Ce processus permet de traiter des messages de formes très différentes, avec une infinité de formulations du langage. On peut alors couvrir de grands volumes de données en production. Mais ce genre de méthodes probabilistes peut aussi être source d’erreur. C’est pourquoi nous le couplons parfois avec des règles métiers pour sécuriser la réponse apportée en production. Plus particulièrement, lorsqu’on veut clôturer un mail informatif, il est impératif qu’aucun message ne soit clôturé à tort.</p>\n<p>Certains cas d’usages sont également assez simples pour être traités uniquement avec des règles métiers. Par règles métiers, on entend la recherche de motifs fixes dans le texte à l’aide d’expressions régulières. Par exemple, pour détecter un remerciement chaleureux, nous rechercherons dans le message le motif « merci beaucoup » ou le mot « infiniment » alors qu’on exclura des mots comme « inacceptable ».</p>\n<h3>Un changement des pratiques des gestionnaires/conseillers au quotidien</h3>\n<p>Depuis la mise en production de Mélusine, nous avons pu faire la preuve que l’intelligence artificielle peut opérer sans faire de l’ombre à l’activité de nos utilisateurs. Nous souhaitions d’ailleurs à cette occasion, recueillir les témoignages de nos utilisateurs sur leur quotidien avec Mélusine. Deux de nos gestionnaires se sont prêtées au jeu des interviews.</p>\n<a href=\"https://medium.com/media/c7c370bac53bf610fd08f630bb1c81e9/href\">https://medium.com/media/c7c370bac53bf610fd08f630bb1c81e9/href</a><p>Julie et Annabelle évoquent notamment comment Mélusine a changé leur quotidien grâce à :</p>\n<ul>\n<li>La <strong>priorisation des mails</strong> : nous pouvons détecter des messages à caractère d’urgence ou au contraire déprioriser certains mails. Cette information est portée à l’attention du gestionnaire/conseiller qui adapte son activité en fonction.</li>\n<li>La <strong>clôture des mails</strong> : les mails à caractère informatifs qui ne nécessitent pas d’action peuvent être clôturés directement. Ils s’affichent toutefois aux yeux de l’utilisateur mais sans nécessiter d’actions. L’utilisateur peut alors lire son contenu rapidement.</li>\n<li>La <strong>réponse automatique: </strong>de manière très marginale, une réponse automatique est apportée pour certains mails qui ne requièrent pas d’accompagnement de la part d’un conseiller. Comme la clôture, le mail émie automatiquement s’affiche dans l’interface sans nécessiter d’actions.</li>\n<li>Le <strong>confort</strong> : au-delà de la priorisation ou la clôture, un gros travail a été réalisé sur la façon d’apporter le plus d’informations possibles sur l’interface du gestionnaire/conseiller. Ainsi, un champ texte est enrichi pour leur donner une première lecture rapide du mail. Apparaissent alors l’expéditeur du mail, les cas d’usages détectés par l’IA (ex : taux d’humidité, rendez-vous détecté, mise en place d’aide à domicile etc.) et le début du mail.</li>\n</ul>\n<p>Autant d’informations qui permettent à l’utilisateur de comprendre rapidement les actions à mener et organiser sa journée.</p>\n<a href=\"https://medium.com/media/9ff9c9cae4abc50beafcfd5a0f137b5c/href\">https://medium.com/media/9ff9c9cae4abc50beafcfd5a0f137b5c/href</a><p>Tous ces apports de l’IA se sont traduits par une adaptation du quotidien des utilisateurs, qui se sont rapidement emparés des informations fournies pour organiser plus sereinement leur journée de travail. Ces améliorations allègent leur activité d’actions simples et répétitives, ce qui les rend plus disponibles pour répondre aux sociétaires.</p>\n<h3>Les perspectives pour l’Intelligence Artificielle</h3>\n<p>Les volumes de flux emails étant en constante croissance, nous avons à cœur d’étendre toujours plus le périmètre de Mélusine. Cela peut passer par l’amélioration de la détection de cas d’usages existants, la mise en place de nouveaux cas d’usages ou par l’exploitation de nouveaux types de données !</p>\n<p>En effet, un mail ce n’est pas que du texte ! Ce sont aussi des pièces jointes. En cette fin d’année 2021, nous mettrons notre premier modèle de typage de pièces jointes en production. L’utilisateur pourra ainsi rapidement savoir si le document associé est une facture, un devis etc… Combiner le contenu du texte et le type de documents élargira également le périmètre de nos cas d’usages.</p>\n<p>Par exemple, aujourd’hui nous ne clôturons que des mails informatifs sans pièce jointe. Jusqu’à maintenant, lorsque le mail contenait une pièce jointe, on ne savait pas ce qu’elle contenait. On ne voulait pas prendre le risque de clôturer un mail contenant des documents importants.</p>\n<p>Mais ! Vous avez sûrement déjà fait l’expérience de ces mails avec des signatures/logos en pièces jointes…elles ne vous sont que rarement utiles. Lorsqu’on saura identifier ces documents à faible valeur, on pourra clôturer un plus grand volume de mails informatifs. Ce qui allègera encore le quotidien du conseiller/gestionnaire, qui pourra se recentrer sur la relation au sociétaire et des tâches à valeur ajoutée.</p>\n<h3>L’Open Source dans tout ça ?</h3>\n<p>Malgré une volonté de partage et transparence sur les outils utilisés, il est parfois difficile de faire évoluer en parallèles nos algorithmes de production et la librairie Open Source. Le facteur principal étant le manque de temps. Pour répondre aux besoins de nos utilisateurs MAIF de façon réactive, nous priorisons le déploiement en interne de Mélusine et, animer une communauté Open Source peut s’avérer chronophage.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mAmfLF6k24ZKtZ2NkDxxOg.png\"></figure><p>C’est pourquoi cette année 2021, nous avons peu contribué à Mélusine Open Source. Nous restons cependant présents pour assurer le support pour répondre à vos interrogations, résoudre des bugs ou intégrer de nouvelles contributions.</p>\n<p>Une seconde raison pour laquelle nous avons peu contribué est que, nous préparons des changements structurels de la librairie. En effet, en étendant le périmètre de Mélusine en interne, nous nous sommes rendu compte, sur certains projets, que nous utilisions du code trop spécifique et non-réutilisable.</p>\n<p>Sur l’année 2022, nous allons entamer des travaux pour rendre notre code plus modulable et réutilisable d’un projet NLP à l’autre. Nous pourrons ensuite vous en faire profiter ! Mais il faudra d’abord que nous éprouvions cette réorganisation en production.</p>\n<p>Cependant, nous sommes toujours enthousiastes à l’idée de recevoir de nouvelles contributions externes pour apporter de nouvelles fonctionnalités !!! Alors n’hésitez pas à nous écrire sur le <a href=\"https://github.com/MAIF/melusine\">Github de Melusine</a> en créant une issue ou tout simplement en nous écrivant dans l’onglet « Conversation ».</p>\n<p>Mélusine continue à évoluer. Au plaisir de vous lire !</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1ce5cd50802b\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/m%C3%A9lusine-un-retour-dexp%C3%A9rience-maif-1ce5cd50802b\">Mélusine, un retour d’expérience MAIF !</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Shapash &amp; ACV : 2 initiatives complémentaires pour une IA explicable",
    "author_id": "Yann Golhen",
    "created_at": "2021-09-01 17:44:10",
    "id": "https://medium.com/p/b211dadbec30",
    "author_username": "Yann Golhen",
    "author_name": "Yann Golhen",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/0*TEVNQ-YQBMCwHZmd",
    "description": "\n<h3>Shapash &amp; ACV : 2 initiatives complémentaires pour une IA explicable</h3>\n<h4>\n<a href=\"https://www.maif.fr/\">MAIF</a> et <a href=\"https://www.quantmetry.com/\">Quantmetry</a> rendent compatibles leurs solutions Open Source pour une IA mieux explicable.</h4>\n<p><em>Cet article a été co-écrit par </em><a href=\"https://www.linkedin.com/in/guillaume-bodiou/\"><em>Guillaume Bodiou</em></a><em>, </em><a href=\"https://www.linkedin.com/in/nicolasbrunel/\"><em>Nicolas Brunel</em></a><em> et </em><a href=\"https://www.linkedin.com/in/yann-golhen\"><em>Yann Golhen</em></a><em>.</em></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*TEVNQ-YQBMCwHZmd\"><figcaption>Photo by <a href=\"https://unsplash.com/@kerenfedida?utm_source=medium&amp;utm_medium=referral\">Keren Fedida</a> on <a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Savoir rendre les algorithmes intelligibles est aujourd’hui l’un des enjeux majeurs de l’IA. Les motivations peuvent être multiples :</p>\n<ul>\n<li>Répondre au besoin des utilisateurs de comprendre les résultats d’une IA ; une nécessité dès lors que ces résultats sont utilisés dans une prise de décision.</li>\n<li>S’assurer de la fiabilité des IA et prévenir les biais éventuels.</li>\n<li>Anticiper la mise en conformité au futur règlement européen (projet publié par la Commission le 21 avril dernier).</li>\n</ul>\n<p>Répondre à ce besoin d’intelligibilité implique d’une part de disposer de mesures fiables, mais aussi de pouvoir les rendre compréhensibles pour des non-experts.</p>\n<p>Afin d’apporter des réponses concrètes à ces questions, la <a href=\"https://www.maif.fr/\"><strong>MAIF</strong></a> et <a href=\"https://www.quantmetry.com/\"><strong>Quantmetry</strong></a> ont lancé deux initiatives complémentaires :</p>\n<ul>\n<li>\n<a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> (<a href=\"https://www.maif.fr/\"><strong>MAIF</strong></a>) s’appuie sur plusieurs types de visualisations afin de rendre accessible les éléments d’explication de n’importe quel modèle.</li>\n<li>\n<a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> (initiative <a href=\"https://www.quantmetry.com/\"><strong>Quantmetry</strong></a>) vise à fiabiliser les calculs d’intelligibilité d’un modèle.</li>\n</ul>\n<p>Nous avons décidé de rendre nos travaux accessibles à tous afin de contribuer à la construction d’une IA plus transparente et maîtrisée. Par cette collaboration, nous visons notamment à :</p>\n<ul>\n<li>Rendre nos 2 packages compatibles prochainement</li>\n<li>Évaluer les écarts entre l’intelligibilité calculée par la méthode <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> et d’autres méthodes existantes sur des données réelles.</li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/863/1*JcXV-ezvB723fjUYvuJDDA.png\"></figure><h3><strong>Shapash</strong></h3>\n<p>Shapash, développée et libérée en open source par MAIF est une librairie python qui propose un ensemble d’outils pour faire parler les modèles boîtes noires et les rendre compréhensibles par tous.</p>\n<p>Depuis son lancement en janvier 2021, la librairie connait un franc succès et fait le tour du monde : 1,3 k⭐️, &gt; 60k downloads.</p>\n<p><a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> permet :</p>\n<ul>\n<li>Au Data Scientist de comprendre facilement ses modèles, de partager et valider son approche avec ses sponsors : Shapash facilite le travail de pédagogie nécessaire à l’adhésion à l’IA dans les organisations.</li>\n<li>A l’utilisateur final de comprendre une recommandation/prévision provenant d’un modèle de ML grâce à un résumé adapté de l’explicabilité locale.</li>\n<li>A un auditeur, un DPO, de comprendre comment est construit chaque modèle déployé en production à travers un rapport standalone.</li>\n</ul>\n<p>Concrètement, Shapash est un wrapper capable de s’appuyer sur différentes librairies d’explicabilité en backend qui propose :</p>\n<ul>\n<li>Des visualisations simples, une Webapp, des fonctionnalités de wording (utiles pour toutes vos variables explicatives catégorielles).</li>\n<li>un rapport html pour documenter vos entrainements de modèles.</li>\n<li>un résumé de l’explicabilité locale.</li>\n<li>un passage en production facilité.</li>\n</ul>\n<blockquote>\n<a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a>, s’appuie par défaut sur un backend <a href=\"https://github.com/slundberg/shap\"><strong>shap</strong></a> qui est aujourd’hui la librairie la plus utilisée pour le calcul de l’explicabilité locale. Mais <a href=\"https://github.com/slundberg/shap\"><strong>shap</strong></a>, à certains égards, présente des limites : stabilité des contributions de shapley, prise en compte des corrélations, causalités entre variables explicatives, …</blockquote>\n<p>Aussi, fidèle à notre logique de librairie ouverte, il nous a paru important de proposer aux utilisateurs de Shapash des alternatives. A ce titre l’intégration d’un backend <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> par <a href=\"https://www.quantmetry.com/\"><strong>Quantmetry</strong></a> est une contribution importante.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/977/1*9gjwQsN_O5T20TRnsGensA.png\"></figure><h3>Plusieurs manières de calculer les valeurs de Shapley</h3>\n<p>De manière générale, nous pouvons représenter tout modèle d’IA comme une fonction mathématique f(X₁, X₂,…,Xp) (éventuellement très simple comme pour une régression linéaire, ou très compliquée comme une forêt aléatoire). Le but de l’intelligibilité est de faire “parler” le modèle en lui posant les questions suivantes :</p>\n<ul>\n<li>Quelles sont les variables importantes globalement pour le modèle ?</li>\n<li>Quelles sont les variables importantes localement pour un individu donné ?</li>\n<li>Quelles variables faut-il modifier et comment pour changer la décision du modèle ?</li>\n<li>…</li>\n</ul>\n<p>Chacune de ces questions (et d’autres encore) appellent des réponses différentes et impliquent des propriétés mathématiques différentes du modèle. Dans le cas de l’intelligibilité dite locale (la question 2), une réponse simple et agnostique du modèle est apportée par les valeurs de Shapley : celles-ci mesurent l’influence sur la prédiction f(x) de chaque variable pour un individu fixé x = (x₁,…,xp). D’autres indicateurs — utilisant par exemple des modèles approchés — permettent de quantifier l’importance locale des variables, mais les valeurs de Shapley font partie des indicateurs de référence les plus couramment utilisés.</p>\n<p>Le but de l’étude menée conjointement par <a href=\"https://www.quantmetry.com/\"><strong>Quantmetry</strong></a> et la <a href=\"https://www.maif.fr/\"><strong>MAIF</strong></a> consiste à évaluer l’impact des méthodes de calcul des valeurs de Shapley dans la qualité des explications. En effet, comme nous allons le rappeler, les valeurs de Shapley utilisées en explicabilité sont définies non seulement à partir de la “formule” prédictive x → f(x), mais impliquent aussi la loi de probabilité des variables explicatives X₁, X₂,…,Xp</p>\n<a href=\"https://medium.com/media/6d7e371aca9dddfc240d1b9fcad14fbb/href\">https://medium.com/media/6d7e371aca9dddfc240d1b9fcad14fbb/href</a><p>Malheureusement, aucune de ces lois n’est connue en pratique, et elles doivent être estimées à partir des données à disposition. Et c’est là que peuvent intervenir des différences très importantes… car selon les estimations utilisées, des valeurs de Shapley très différentes peuvent être obtenues, alors que le modèle et les données utilisées sont les mêmes ! Ainsi, selon les hypothèses faites sur ces distributions inconnues, les approximations des valeurs de Shapley seront de plus ou moins bonne qualité.</p>\n<p>Dans l’article <a href=\"https://arxiv.org/abs/2106.03820\">Accurate and robust Shapley Values for explaining predictions and focusing on local important variables</a>, il est montré que le calcul utilisé par la librairie <a href=\"https://github.com/slundberg/shap\"><strong>SHAP</strong></a> utilise un estimateur qui est valable essentiellement quand toutes les variables Xᵢ sont indépendantes. C’est pour cela qu’un autre estimateur, plus général et plus précis, a été proposé et implémenté dans la librairie <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> (Active Coalition of Variables). Les comparaisons sur des modèles standards simples montrent :</p>\n<ul>\n<li>Des différences très significatives entre les explications de <strong>SHAP</strong> et les vraies explications (calculables théoriquement sur certains modèles)</li>\n<li>Les explications <a href=\"https://github.com/salimamoukou/acv00\">d’<strong>ACV</strong></a> sont beaucoup plus proches des vraies explications et beaucoup moins dispersées.</li>\n</ul>\n<p>L’objectif est alors d’évaluer l’impact de ces écarts pour l’explicabilité de modèles en production, basé sur des données réelles et bénéficiant d’un contexte métier permettant de les interpréter.</p>\n<p>Les valeurs de Shapley servent à attribuer un score d’importance locale aux différentes variables, qui permet ensuite de les classer pour identifier le groupe de variables les plus importantes. Nous nous posons alors deux questions :</p>\n<ul>\n<li>Est-ce que les différentes erreurs d’approximation des librairies <a href=\"https://github.com/slundberg/shap\"><strong>SHAP</strong></a> et <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> sont discordantes (ordre de grandeurs et signes similaires…)</li>\n<li>Est-ce que ces mêmes erreurs d’approximation vont jusqu’à modifier l’identification et le classement des variables les plus importantes ? Dans ce cas, les classements obtenus par <a href=\"https://github.com/slundberg/shap\"><strong>SHAP</strong></a> et <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> restent ils concordants entre eux ?</li>\n</ul>\n<p>In fine, il s’agit bien sûr de déterminer quelle librairie fournit les analyses les plus cohérentes avec les expertises métiers.</p>\n<p>Un autre point que nous cherchons à quantifier est l’impact de la mauvaise gestion par SHAP des variables catégorielles : en effet, la sommation des valeurs de Shapley de <a href=\"https://arxiv.org/abs/2106.03820\">“variables catégorielles One-Hot-Encoded” est mathématiquement fausse</a>. La librairie <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> donne la possibilité de gérer correctement ce type de variables en permettant de calculer les valeurs de Shapley de groupes de variables. Ainsi une autre famille de questions que nous abordons est d’évaluer l’impact de ces différences (<a href=\"https://github.com/slundberg/shap\"><strong>SHAP</strong></a> vs <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a>) pour l’identification de variables importantes.</p>\n<p>Enfin, un dernier point que nous souhaitons explorer est la possibilité d’imposer l’estimation d’un faible nombre de valeurs de Shapley correspondant à un petit de nombre de variables actives (les autres variables constituant le null-set). Cet ensemble actif est déterminé par le calcul de la “Same Decision Probability”, qui permet de déterminer les variables les plus influentes sur une prédiction donnée. De la même manière que dans les autres cas, nous cherchons à déterminer et à valider avec de vraies explications métiers, si des estimations “sparses” peuvent capturer l’essentiel des résultats.</p>\n<p>Ainsi cette étude contient 3 phases distinctes qui vont permettre de donner des recommandations sur l’une ou l’autre librairie pour le calcul des valeurs de Shapley. Nous souhaitons notamment pouvoir caractériser les individus pour lesquels ces écarts sont très importants car nous partons du principe qu’une IA de confiance doit pouvoir expliquer tous les individus de la même façon, de manière fiable.</p>\n<p>Pour finir, nous précisons que les algorithmes de <a href=\"https://github.com/salimamoukou/acv00\"><strong>ACV</strong></a> supposent que les modèles sont à base d’arbres (catboost, sklearn, xgboost). Nous comparons alors avec le TreeExplainer de SHAP pour avoir la meilleure explication, mais comme ces modèles font partie des plus déployés, le champ d’applications de la libraire ACV reste vaste.</p>\n<h3>Conclusion</h3>\n<p>Nous sommes convaincus de la nécessité de disposer d’outils fiables et transparents pour apporter des réponses à ces questions centrales d’explicabilité. Si le sujet vous intéresse, nous serons ravis de voir la communauté de contributeurs s’élargir.</p>\n<p><a href=\"https://www.linkedin.com/in/guillaume-bodiou/\"><em>Guillaume Bodiou</em></a><em>, </em><a href=\"https://www.linkedin.com/in/nicolasbrunel/\"><em>Nicolas Brunel</em></a><em> et </em><a href=\"https://www.linkedin.com/in/yann-golhen\"><em>Yann Golhen</em></a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b211dadbec30\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-acv-2-initiatives-compl%C3%A9mentaires-pour-une-ia-explicable-b211dadbec30\">Shapash &amp; ACV : 2 initiatives complémentaires pour une IA explicable</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Shapash 1.4.2: Des groupes de variables pour une compréhension facilitée de vos modèles",
    "author_id": "Thomas Bouche",
    "created_at": "2021-07-05 10:11:04",
    "id": "https://medium.com/p/3bfa4351f8d2",
    "author_username": "Thomas Bouche",
    "author_name": "Thomas Bouche",
    "thumbnail": "https://cdn-images-1.medium.com/max/600/1*GmBC9DcEfKbKxt_K8ewKEg.gif",
    "description": "\n<h3>La version 1.4.2 de <a href=\"https://github.com/MAIF/shapash\">Shapash</a> est désormais disponible et la librairie s’enrichit d’une fonctionnalité de groupement de variables pour prendre de la hauteur sur l’explicabilité d’un modèle riche en variables !</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*GmBC9DcEfKbKxt_K8ewKEg.gif\"><figcaption>Webapp Shapash</figcaption></figure><p>Un modèle apprend de datasets qui peuvent contenir des dizaines ou centaines de variables, avec des variables qui ont des thématiques communes. Regrouper ces variables dans l’explicabilité du modèle permet une compréhension plus facile du modèle et une meilleure navigation dans les variables et leurs influences sur le modèle.</p>\n<p>Avec la nouvelle version de Shapash, il est désormais possible de spécifier un dictionnaire de groupe de variables, qui est utilisé dans l’analyse de l’explicabilité.</p>\n<p>Nous allons illustrer ces fonctionnalités sur un cas d’usage avec le dataset public Kaggle : <a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\">House Prices — Advanced Regression Techniques | Kaggle</a>, (dataset d’exemple repris dans les <a href=\"https://github.com/MAIF/shapash/tree/master/tutorial\"><strong>tutoriels</strong></a> Shapash). <br>Ce dataset contient environ 70 variables descriptives d’une maison qui présentent des informations sur l’aspect et l’équipement de la maison, la localisation, les surfaces des pièces,… Par exemple, 6 variables décrivent le garage avec le type, la finition, la qualité, la surface,… Pour analyser l’explicabilité du modèle, on peut regrouper ces 6 variables sous un même intitulé “garage”, et avoir une vision globale de ce groupe de variable.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*9qv8Tw9t-Xt3L6-l5TbPEw.gif\"><figcaption>Features importance avec ou sans groupement de variables</figcaption></figure><ul><li><strong>Comment grouper les variables dans Shapash ?</strong></li></ul>\n<p>Pour avoir accès aux différentes fonctionnalités de groupement de variables, il suffit de déclarer les variables à grouper et le nom du groupe de variables dans un dictionnaire, et de déclarer ce dictionnaire lors de la compilation de Shapash.</p>\n<pre><strong>features_groups</strong> = {<br>    \"<strong>location</strong>\": [\"MSZoning\", \"Neighborhood\", \"Condition1\", Condition2\"],<br>    \"<strong>garage</strong>\": [\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageArea\",\"GarageQual\",\"GarageCond\"],    <br>}</pre>\n<pre>from shapash.explainer.smart_explainer import SmartExplainer<br>xpl = SmartExplainer(features_dict=house_dict)<br>xpl.compile(<br>    x=X_test,<br>    model=regressor,<br>    preprocessing=encoder,<br><strong>features_groups=features_groups</strong><br>)</pre>\n<ul><li><strong>Comment naviguer dans le Webapp pour explorer les groupes ?</strong></li></ul>\n<p>Pour lancer la Webapp, le code est le suivant :</p>\n<pre>app = xpl.run_app(title_story='House Prices')</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/128/0*uzGDkCDqBtGn4hB1.gif\"><figcaption>Bouton d’activation des groupements</figcaption></figure><p>Dans la Webapp, ce bouton permet d’activer ou de désactiver les groupements des variables.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*WEbSRM9URV59Pp81S4cq-g.gif\"><figcaption>Navigation de features importance et feature contribution dans la Webapp</figcaption></figure><p>Dans ce graphique des <em>features importance</em>, les variables en orange et en gras représentent les groupes de variables. Pour avoir un détail de chaque variable du groupe, il faut cliquer sur la barre orange.</p>\n<p>Pour revenir sur l’ensemble des variables, il faut cliquer sur le fond blanc du graphique.</p>\n<p>Lorsque l’on sélectionne un groupe dans le graphique des <em>feature importances</em>, le graphique de contribution (Feature Contribution) du groupe de variables correspond à une projection sur l’axe x en utilisant une réduction de dimension t-sne. Et sur l’axe y, nous retrouvons la somme des contributions. En pointant le curseur sur un point, nous retrouvons le détail des variables les plus contributrices du groupe.</p>\n<p>Si on clique sur l’une des variables du groupe dans le graphique des <em>feature importances, </em>le contribution plot affiche les contributions associées à la feature en lieu et place de la projection t-sne.</p>\n<ul><li><strong>Restitution locale du groupement de variables :</strong></li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*9k_kwlQIvhQfM2y-Fe7EAg.gif\"><figcaption>Navigation sur le local plot de la Webapp</figcaption></figure><p>Le regroupement de variables s’applique également aux contributions locales. Il permet d’avoir une vision synthétique des variables contributrices.</p>\n<p>Sur l’exemple présenté sur le graphique, le groupement de variables permet de montrer que l’ensemble des variables de surfaces contribuent à une baisse de prix de -13 000$ par rapport à la moyenne. Que les variables de localisation (+3 000$) et les variables du garage (+2 000$) contribuent positivement. De plus, les barres des contributions cachées sont très faibles (Hidden Positive contributions et Hidden Negative Contributions) avec le groupement de variables, ce qui montre que la globalité des contributions sont représentées.</p>\n<p>Pour une restitution des contributions locales en mode API ou mode batch, les groupes de variables sont intégrés dans les objets Smartexplainer (methode to_pandas) et Smartpredictor (methode summarize). Ils peuvent être désactivés avec l’option “use_groups=False”.</p>\n<pre>predictor = xpl.to_smartpredictor()<br>predictor.add_input(sample_input)<br>predictor.summarize()</pre>\n<p>Pour les groupes de variables, la valeur est un dictionnaire de l’ensemble des valeurs des variables du groupe.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ylLyUXa5Oi9C7Djl7DF64w.png\"><figcaption>Dataframe des contributions</figcaption></figure><p>Pour chaque individu, la méthode summarize() du Smartpredictor fournit un DataFrame qui contient les variables triées par importance dans la contribution. Sur ces exemples ci-dessus, les principales variables contributrices, sont des variables groupées, ce qui permet de résumer plus facilement la prédiction.</p>\n<p>Avec ces nouvelles fonctionnalités, nous espérons que Shapash puisse encore plus faciliter la compréhension d’un modèle de machine learning.</p>\n<p>Pour plus de détails, nous vous invitons à découvrir le <a href=\"https://github.com/MAIF/shapash/blob/master/tutorial/common/tuto-common01-groups_of_features.ipynb\"><strong>tutoriel</strong></a> sur le GitHub <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a><strong>.</strong></p>\n<h3>💡Partagez vos propres idées !</h3>\n<p>N’hésitez pas à vous rendre sur le GitHub de <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> : vous y trouverez une documentation exhaustive sur cette nouvelle fonctionnalité. Vous pourrez aussi y laisser vos messages (onglet discussions) et contribuer à la solution en partageant vos propres templates ou toute autre idée.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3bfa4351f8d2\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-1-4-2-des-groupes-de-variables-pour-une-compr%C3%A9hension-facilit%C3%A9e-de-vos-mod%C3%A8les-3bfa4351f8d2\">Shapash 1.4.2: Des groupes de variables pour une compréhension facilitée de vos modèles</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Shapash 1.3.2 pour une IA plus Auditable !",
    "author_id": "Yann Golhen",
    "created_at": "2021-04-15 08:50:04",
    "id": "https://medium.com/p/3c3e7e375775",
    "author_username": "Yann Golhen",
    "author_name": "Yann Golhen",
    "thumbnail": "https://cdn-images-1.medium.com/max/800/1*Hdg8IppDSKW1ircMMDELdQ.gif",
    "description": "\n<h3>Shapash 1.3.2 pour une IA plus Auditable !</h3>\n<h4>\n<strong>La version 1.3.2 de </strong><a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a><strong> est désormais disponible et la librairie s’enrichit d’une fonctionnalité attendue : Le </strong><a href=\"https://shapash.readthedocs.io/en/latest/report.html\"><strong>Shapash Report</strong></a><strong>, un document html qui contribue à rendre vos modèles auditables !</strong>\n</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*Hdg8IppDSKW1ircMMDELdQ.gif\"></figure><p><a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a><strong> </strong>est une librairie Python libérée par les équipes data MAIF en Janvier 2021 pour rendre les modèles de Machine Learning compréhensibles par le plus grand nombre. Concrètement, <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> propose différentes fonctionnalités qui permettent :</p>\n<ul>\n<li>au Data Scientist d’analyser facilement ses modèles, de partager et de valider son approche avec ses commanditaires</li>\n<li>à l’utilisateur final de comprendre une recommandation/prévision provenant d’un modèle de ML grâce à un résumé adapté des critères qui en sont à l’origine</li>\n</ul>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-une-nouvelle-solution-ossbymaif-pour-une-intelligence-artificielle-plus-transparente-c216f9ddb2e9\"><em>Retrouvez la présentation générale de Shapash dans ce post.</em></a></p>\n<p>Depuis son lancement, vous êtes de plus en plus nombreux à l’utiliser et à nous faire des retours extrêmement positifs et nous vous en remercions ! <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> a déjà fait le tour du monde ! Ceci renforce notre volonté de partager en Open Source nos travaux et de contribuer à une utilisation éthique de la Data et à une IA maitrisée.</p>\n<p><strong>Aujourd’hui, la version 1.3.2 est disponible et </strong><a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a><strong> permet désormais au Data Scientist de documenter chaque modèle qu’il passe en production</strong>. En quelques lignes de code, il fait figurer dans un rapport html toutes les informations qui concernent son modèle (et sa performance associée), les datas qu’il utilise, sa stratégie d’apprentissage, … ce rapport est conçu pour être partagé facilement avec un DPO, un service audit interne, contrôle des risques, conformité ou à toute personne qui souhaite comprendre ses travaux.</p>\n<h3>Un peu de contexte :</h3>\n<blockquote>L’intelligence artificielle fait peur : “Quel usage est fait des données personnelles ? A quelle fin est développée IA ? quel est son impact sur l’emploi ? sur nos libertés ? …”</blockquote>\n<p>Autant de questions qui restent souvent en suspend et qui laissent place à toutes les spéculations. Il s’agit là d’un sujet d’actualité et nombreux sont les acteurs qui s’en saisissent.</p>\n<p>Les pouvoirs publics tout d’abord : En France, l’ACPR a publié en 2020 un <a href=\"https://acpr.banque-france.fr/consultation-sur-le-document-de-reflexion-ia-de-lacpr-les-seminaires-scientifiques-de-juillet\">document de réflexion sur la gouvernance des algorithmes d’intelligence artificielle</a>. L’Union Européenne a posé un premier cadre avec le RGPD, cadre qui pourrait prochainement être complété par une règlementation sur l’IA qui aborderait notamment les thématiques de la gouvernance, de “l’auditabilité” et du contrôle.</p>\n<p>Au-delà du cadre légal, des organisations œuvrent pour une Data Science Responsable et de Confiance. Par exemple : <a href=\"https://assessment.substra.ai/fr/\"><strong>Substra Foundation</strong></a><strong> </strong>propose un questionnaire qui permet à chaque entreprise d’évaluer en autonomie sa pratique de la Data Science et d’identifier des axes de progrès.</p>\n<p>Enfin, certaines entreprises privées sont actrices d’une IA de confiance au sein de leur organisation. Quelques grands groupes français se sont dotés de dispositifs de gouvernance de l’éthique de l’intelligence artificielle. Sur ce sujet, le collectif Impact IA a publié en fin d’année 2020 un <a href=\"https://www.impact-ai.fr/guideiaconfiance/\">guide</a> qui présente des cas concrets de mise en place d’une gouvernance pour une IA de confiance. Enfin, d’autres acteurs ont mis en place des guides de bonnes pratiques et les partagent.</p>\n<p>A la MAIF nous sommes très investis dans le développement d’une IA de confiance au service de l’humain. Shapash a été développée dans cette intention et rend compréhensible par tous les recommandations formulées par des modèles de Machine Learning réputés “Black Box”. Avec cette nouvelle version, les équipes data MAIF ont souhaité aller plus loin en contribuant à ce sujet majeur de “l’auditabilité” des modèles, en facilitant la documentation systématique de ces derniers à l’aide de templates.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/868/1*6w8ZgGnSmvxTUsKJdxwSEA.png\"></figure><h3>Le <em>Shapash Report </em>:</h3>\n<p>Le <a href=\"https://shapash.readthedocs.io/en/latest/report.html\"><em>Shapash Report</em></a> est un document html “Standalone” généré à l’aide d’une ligne de code par le Data Scientist au moment où il déploie son modèle en production. Celui-ci lui permet de documenter son projet et de figer dans une « photographie à l’instant T » toutes les informations relatives à l’entrainement de son modèle et aux étapes en amont (dataprep, cadrage,…).</p>\n<p>Ce rapport aide à une meilleure gouvernance de l’IA en documentant finement chaque algorithme déployé. Il permet à chacun au sein de l’organisation de comprendre pourquoi, comment, avec quelles données et à quelle fin a été construit son modèle.</p>\n<p>Nous espérons qu’il sera une aide précieuse pour l’audit des modèles et pour une meilleure gouvernance de l’IA !</p>\n<h4>Un outil ouvert : Chaque organisation peut adapter le contenu de son Shapash Report.</h4>\n<p>En attente d’une règlementation qui précise le contenu type pour cette documentation, il était important pour nous de proposer une solution ouverte. Ainsi, chaque entreprise peut s’approprier l’outil et définir son propre “standard” que chaque data scientist mettra en oeuvre dans ses projets.</p>\n<h4>Une proposition de Template</h4>\n<p>Shapash 1.3.2 propose un template que chacun peut adapter. Vous retrouverez sur le repo Github du projet un tutoriel vous indiquant comment mettre en oeuvre ce template et comment le modifier à votre guise. Dans l’exemple que nous proposons figurent les informations suivantes :</p>\n<ul><li>Informations générales : L’intitulé du projet, sa description, sa finalité, qui a travaillé au développement du modèle, à quelle date…</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/505/1*L0izmJD3sdCUiAebSApRxg.png\"></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/621/1*1sWUm4UbIeRbjrA9BX1BAQ.png\"></figure><ul>\n<li>Dataprep : D’où proviennent les données, où puis-je trouver les programmes de data preparation,…</li>\n<li>Features Engineering et stratégie d’entrainement : Quelle a été la stratégie mise en oeuvre, quels sont les programmes associés à cette partie.</li>\n<li>Informations relatives au modèle : Quel type de modèle ? Quels sont les hyper-paramètres retenus ?</li>\n<li>Analyse des datasets d’entrainement et test : Descriptions de toutes les features introduites dans le modèle et analyse des corrélations.</li>\n<li>Explicabilité globale du modèle : Quelles sont les Top features du modèle ? Quelle influence a chacune d’elle sur la recommandation/prévision ?</li>\n<li>La performance du modèle : Restitution des métriques associées au modèle, distribution de la prévision sur le dataset de test.</li>\n</ul>\n<p>Le contenu de ce rapport est très riche. Aussi, pour faciliter la navigation <a href=\"https://shapash.readthedocs.io/en/latest/report.html\"><em>Shapash Report</em></a> propose un volet “Table des matières” ainsi que différents boutons menus.</p>\n<p>Le <a href=\"https://shapash.readthedocs.io/en/latest/report.html\"><em>Shapash Report</em></a> bénéficie de toutes les fonctionnalités de wording des data de <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a><strong> </strong>: Les libellés fonctionnels associés à chaque feature sont restitués dans ce document html pour que le contenu partagé soit compréhensible par tous et notamment par ceux qui n’ont pas pris part à la construction du modèle.</p>\n<h4>💡Partagez vos propres idées !</h4>\n<p>N’hésitez pas à vous rendre sur le GitHub de <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> : vous y trouverez une documentation exhaustive sur cette nouvelle fonctionnalité. Vous pourrez aussi y laisser vos messages (onglet discussions) et contribuer à la solution en partageant vos propres templates ou toute autre idée. Et n’hésitez pas à mettre une étoile sur GitHub si vous aimez le projet !</p>\n<p>Puisse Shapash contribuer au développement d’une IA de confiance !</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3c3e7e375775\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-1-3-2-pour-une-ia-plus-auditable-3c3e7e375775\">Shapash 1.3.2 pour une IA plus Auditable !</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Bienvenue à Thoth !",
    "author_id": "Benjamin Cavy",
    "created_at": "2021-03-08 09:45:11",
    "id": "https://medium.com/p/48dfcf1dbd42",
    "author_username": "Benjamin Cavy",
    "author_name": "Benjamin Cavy",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*kS0SAyWM5WYWnymca1hazg.jpeg",
    "description": "\n<h3>Bienvenue à Thoth !</h3>\n<p><strong>English version of this article may be found </strong><a href=\"https://medium.com/oss-by-maif/open-sourcing-thoth-173c95502229\"><strong>here</strong></a><strong>.</strong></p>\n<p>Aujourd’hui nous libérons <a href=\"https://github.com/MAIF/thoth\">Thoth</a>, notre bibliothèque Java qui vous fournit l’ensemble des outils permettant d’implémenter l’event sourcing dans votre application.</p>\n<blockquote>Power your Java Apps with Event Sourcing</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kS0SAyWM5WYWnymca1hazg.jpeg\"></figure><p>Plutôt que de maintenir un état applicatif, l’Event Sourcing propose de se concentrer sur “ce qui s’est passé” en stockant les événements qui ont mené à l’état applicatif plutôt que l’état en lui-même.</p>\n<p>Cette approche offre un log d’audit <em>by-design</em> pour l’application.</p>\n<p>Ce pattern fonctionne bien dans des architectures orientées événements : les événements peuvent être publiés tels quels.</p>\n<p>L’event sourcing est également très adapté à la mise en place du <a href=\"https://martinfowler.com/bliki/CQRS.html\"><strong>CQRS</strong></a>, les projections de lecture peuvent être créées et mises à jour en consommant les événements.</p>\n<p><strong>Thoth</strong> vous permet de gérer une publication d’événements robuste : les événements sont stockés en base de données avant d’être publiés dans Kafka.<br>La publication dans Kafka sera retentée jusqu’à ce qu’elle réussisse</p>\n<p>Thoth permet de définir deux types de projections :</p>\n<ul>\n<li>Les projections en “Temps Réel” qui sont mises à jour dans la même transaction que l’événement.</li>\n<li>Les projections “Cohérentes à terme” (eventually consistent) qui sont mises à jour de manière asynchrone en consommant Kafka.</li>\n</ul>\n<p>Plus d’informations ici : <a href=\"https://github.com/maif/thoth\">https://github.com/maif/thoth</a><br>Vous trouverez des démos ici : <a href=\"https://github.com/MAIF/thoth/tree/master/demo\">https://github.com/maif/thoth/demo</a></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*qa_A_P0a7Pb9V5tJALTu0g.png\"></figure><p>L’autre bonne nouvelle, c’est que Thoth vient avec 3 autres bibliothèques Java que vous pouvez utiliser avec Thoth ou indépendamment :</p>\n<ul>\n<li>\n<a href=\"https://github.com/MAIF/jooq-async\">jooq async</a> : une intégration de vertx, vavr et jooq</li>\n<li>\n<a href=\"https://github.com/MAIF/functional-json\">functional json</a> : une bibliothèque fonctionnelle de parsing JSON basée sur Jackson</li>\n<li>\n<a href=\"https://github.com/MAIF/functional-validation\">functional validation</a> : une bibliothèque fonctionnelle de validation des beans</li>\n</ul>\n<h3><strong>Jooq Async</strong></h3>\n<p>Jooq Async vous permet d’intégrer <em>Jooq</em>, le client <em>Vertx Postgresql</em> et <em>Vavr</em>. Grâce à cette bibliothèque, vous pouvez construire des requêtes à l’aide de Jooq et les exécuter dans un thread pool de taille réduite avec Vertx.</p>\n<p>Plus d’informations ici : <a href=\"https://github.com/MAIF/jooq-async\">https://github.com/MAIF/jooq-async</a></p>\n<h3><strong>Functional Json</strong></h3>\n<p>Functional Json vous permet de manipuler du JSON selon un paradigme fonctionnel.</p>\n<p>Il propose des méthodes utilitaires pour écrire / lire des noeuds JSON et permet une gestion élégante des erreurs.</p>\n<p>Plus d’informations ici : <a href=\"https://github.com/MAIF/functional-json\">https://github.com/MAIF/functional-json</a></p>\n<h3><strong>Functional Validation</strong></h3>\n<p><strong>Functional Validation</strong> vous permet de définir des validations atomiques de beans et de les composer. Au final on obtient une validation réussie ou l’ensemble des erreurs qui ont été rencontrées au cours de la validation.</p>\n<p>Functional Validation est compatible avec la spécification <em>Bean Validation</em> (<em>JSR 303</em>) et vous pouvez la composer avec une validation manuelle.</p>\n<p>Plus d’informations ici : <a href=\"https://github.com/MAIF/functional-validation\">https://github.com/MAIF/functional-validation</a></p>\n<blockquote>L’event sourcing est au cœur de plusieurs de nos applications. Nous espérons que Thoth répondra à votre besoin et vous plaira !</blockquote>\n<h3>Un Meetup pour découvrir Thoth</h3>\n<p>Si vous souhaitez voir Thoth en action, nous vous proposons un meetup #OSSbyMAIF en ligne sur le sujet le 24 mars à 17h. <a href=\"https://bit.ly/thoth-oss-meetup\">Vous pouvez vous inscrire ici</a>.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=48dfcf1dbd42\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/bienvenue-%C3%A0-thoth-48dfcf1dbd42\">Bienvenue à Thoth !</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Open sourcing Thoth",
    "author_id": "larousso",
    "created_at": "2021-03-08 09:40:43",
    "id": "https://medium.com/p/173c95502229",
    "author_username": "larousso",
    "author_name": "larousso",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/0*YqkkP1ZqFJVhWHv9",
    "description": "\n<p><strong>La version Française de cet article est disponible </strong><a href=\"https://medium.com/oss-by-maif/bienvenue-%C3%A0-thoth-48dfcf1dbd42\"><strong>ici</strong></a><strong>.</strong></p>\n<p>Today we open <a href=\"https://github.com/MAIF/thoth\">Thoth</a>, our Java library which offers a toolkit to implement event sourcing in your Java application.</p>\n<blockquote>Power your Java Apps with Event Sourcing</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YqkkP1ZqFJVhWHv9\"></figure><p>Rather than maintaining an up-to-date application state, event sourcing focuses on what happened by storing events.</p>\n<p>This approach provides <em>by-design</em> audit log for the application.</p>\n<p>It is also very well suited for event-driven architectures : events can be published as is.</p>\n<p>It plays well with CQRS : building and maintaining read projections is done by consuming events.</p>\n<p>Thoth guaranties that:</p>\n<ul>\n<li>Events will be written in the database before being published in Kafka (to prevent failure)</li>\n<li>Publication in Kafka will be reattempted until it succeeds</li>\n</ul>\n<p>It provides capabilities of defining two types of projections :</p>\n<ul>\n<li>“Real time” projections, that are updated in the same transaction as the events</li>\n<li>“Eventually consistent” projections, updated asynchronously by consuming Kafka</li>\n</ul>\n<p>More information is available here : <a href=\"https://github.com/maif/thoth\">https://github.com/maif/thoth</a></p>\n<p>You can also find demos here : <a href=\"https://github.com/MAIF/thoth/tree/master/demo\">https://github.com/MAIF/thoth/tree/master/demo</a></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/715/1*qa_A_P0a7Pb9V5tJALTu0g.png\"></figure><p>The other good news is Thoth comes with 3 other Java libraries which you may use with Thoth or independantly :</p>\n<ul>\n<li>\n<a href=\"https://github.com/MAIF/jooq-async\">jooq async</a> : some glue between <em>Vertx</em>, <em>Vavr</em> and <em>Jooq</em>\n</li>\n<li>\n<a href=\"https://github.com/MAIF/functional-json\">functional json</a> : a functional way to parse JSON using <em>Jackson</em>\n</li>\n<li>\n<a href=\"https://github.com/MAIF/functional-validation\">functional validation</a> : a functional way to validate beans</li>\n</ul>\n<h3>Jooq Async</h3>\n<p><strong>Jooq Async</strong> allows you to use <em>Jooq</em>, <em>Vertx Postgresql</em> client and <em>Vavr</em> together. With this lib, you can build queries with the power of <em>Jooq</em> and run it on a small thread pool using <em>Vertx</em>.</p>\n<p>More info here : <a href=\"https://github.com/MAIF/jooq-async\">https://github.com/MAIF/jooq-async</a></p>\n<h3>Functional Json</h3>\n<p><strong>Functional Json</strong> helps you to manipulate JSON in a functional way.</p>\n<p>It provides flowless helpers to write / read Jackson node, and elegant error handling.</p>\n<p>More info here : <a href=\"https://github.com/MAIF/functional-json\">https://github.com/MAIF/functional-json</a></p>\n<h3>Functional Validation</h3>\n<p><strong>Functional Validation</strong> allows you to define atomic validation and compose them. At the end, you will have a successful validation or all the errors that have been collected.</p>\n<p>You may also use Bean Validation JavaEE specification (JSR 303) and combine it with manual validation.</p>\n<p>More info here : <a href=\"https://github.com/MAIF/functional-validation\">https://github.com/MAIF/functional-validation</a></p>\n<blockquote>Event sourcing powers a lots of our application. We hope Thoth will fit your needs and that you will enjoy it !</blockquote>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=173c95502229\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/open-sourcing-thoth-173c95502229\">Open sourcing Thoth</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Shapash: MAIF releases a new solution for a more transparent AI",
    "author_id": "Yann Golhen",
    "created_at": "2021-01-15 18:59:32",
    "id": "https://medium.com/p/500a5589b1f4",
    "author_username": "Yann Golhen",
    "author_name": "Yann Golhen",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*xqa_FsCew8eSFb5mt4bseQ.png",
    "description": "\n<h3>Shapash : MAIF releases a new open source solution for a more transparent AI</h3>\n<p>MAIF, a french mutual insurance company (est. 1934), has been contributing to open-source for a few years. We released two solutions, <a href=\"https://github.com/MAIF/izanami\">Izanami </a>and <a href=\"https://github.com/MAIF/otoroshi\">Otoroshi</a> which are components of our micro-services platform. Since 2019, we also share our work in the field of artificial intelligence, our first release was <a href=\"https://github.com/MAIF/melusine\">Melusine</a>, a tool for french langage email processing.</p>\n<p>We are now releasing <a href=\"https://github.com/MAIF/shapash\">Shapash</a>, a solution which aims to make AI algorithms more transparent and understandable . Thus, it contributes to the <strong>ethical use of data.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xqa_FsCew8eSFb5mt4bseQ.png\"></figure><h4>Elements of context</h4>\n<p>In France, a lot of people <a href=\"https://korii.slate.fr/et-caetera/impact-ai-ifop-etude-francais-et-ia-confiance-besoin-information\">are suspicious with AI</a>. This suspicion is increased by Big Data which provides more data which can be used to train AI algorithms.</p>\n<p>This comes with several risks : misusage of private data, discriminatory biases … AI may also turn into unethical surveillance systems.</p>\n<p>Within the European Union, public authorities are aware of these risks. They deal with these issues both at a European level with the GDPR and at a French level e.g. with the <a href=\"https://www.cnil.fr/\">CNIL</a> (French data protection agency).</p>\n<h4>Why we have made Shapash ?</h4>\n<p>At MAIF, as an insurer, we’ve been using data for a long time, to offer personalized advice to our customers as well as to control insurance risks. Because of our history, as a committed mutual insurance company and because we believe that companies should be responsible for their use of data, we are particularly involved in ethical usage of data.</p>\n<p>We want our AI algorithms to be transparent because we believe it is essential to build and maintain trust in AI.</p>\n<p>We have also been studying for a few years <strong>how Data science models can be more intelligible and understandable</strong>. This is a growing field of study, and several relevant open-source contributions have already been published about it. However, they mainly target data practitioners and specialists.</p>\n<p>With <strong>Shapash</strong>, <strong>MAIF data scientists wanted to share a solution for everyone</strong>, no matter their data background.</p>\n<p>At MAIF, we use <strong>Shapash</strong> to :</p>\n<ul>\n<li>Help data experts and non-experts to <strong>communicate</strong> <strong>better</strong>\n</li>\n<li>Make it easier and faster for MAIF’s data scientists to understand how models they develop work.</li>\n</ul>\n<p>We believe that <strong>Shapash </strong>had to be open-sourced.</p>\n<blockquote>We want to share a solution for all, no matter their data background.</blockquote>\n<h4>What is Shapash ?</h4>\n<p><strong>Shapash </strong>a Python library that helps to make Machine Learning models more transparent and understood by everyone!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/696/1*oaJTad5H3PZk5oUNrcoXag.gif\"><figcaption>Shapash Monitor Demo</figcaption></figure><p>Concretely, it is an overlay to other intelligibility libraries (Shap, Lime) that:</p>\n<ul>\n<li>Displays understandable results with easy-to-read and simple wording and visualization, adapted to everyone.</li>\n<li>Displays an interface that helps to explore different features of a model and offers navigation between global and local explicability. This interface is particularly useful to animate workshops and answer questions on how ML models work.</li>\n<li>Summarizes local explicability to make it useful in an operational context. This summary is adaptable to different use cases and can be exported.</li>\n<li>Is open! <strong>Shapash </strong>is used for Regression, Classification, and fits a multitude of Machine Learning libraries, feature encoding (inverse encoding), usable with contributions calculated by Lime, Shap, …</li>\n</ul>\n<p><strong>Shapash can be used for all kinds of use cases : health, business, marketing, …</strong></p>\n<p>Please visit <a href=\"https://github.com/MAIF/shapash\">Shapash’s GitHub</a> : you will there find more exhaustive documentation of the library’s features as well as a <a href=\"https://shapash-demo.ossbymaif.fr/\">demo</a> of the Web App Shapash Monitor for a quick test! And do not hesitate to give us a star on GitHub if you like the project!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=500a5589b1f4\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-maif-releases-a-new-solution-for-a-more-transparent-ai-500a5589b1f4\">Shapash: MAIF releases a new solution for a more transparent AI</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Shapash : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus transparente",
    "author_id": "Yann Golhen",
    "created_at": "2021-01-11 14:37:31",
    "id": "https://medium.com/p/c216f9ddb2e9",
    "author_username": "Yann Golhen",
    "author_name": "Yann Golhen",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*xqa_FsCew8eSFb5mt4bseQ.png",
    "description": "\n<h3>Shapash : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus transparente</h3>\n<p><strong><em>Dear English-language readers, you will find an English version of this article </em></strong><a href=\"https://medium.com/oss-by-maif/shapash-maif-releases-a-new-solution-for-a-more-transparent-ai-500a5589b1f4\"><strong><em>here</em></strong></a><strong><em>.</em></strong></p>\n<p>MAIF contribue depuis plusieurs années à l’Open source. Les briques <a href=\"https://github.com/MAIF/otoroshi\"><strong>Otoroshi</strong></a> et <a href=\"https://github.com/MAIF/izanami\"><strong>Izanami</strong></a> notamment, sont les ambassadeurs de notre plateforme de micro-services. Depuis 2019, notre mutuelle partage aussi ses travaux sur le domaine l’intelligence artificielle : c’est le cas avec <a href=\"https://github.com/MAIF/melusine\"><strong>Melusine</strong></a> pour le traitement des emails.</p>\n<p>Aujourd’hui c’est la solution <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> que nous vous proposons de découvrir, avec pour ambition de rendre le recours aux algorithmes plus transparent et de contribuer ainsi à <strong>une utilisation éthique de la data.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xqa_FsCew8eSFb5mt4bseQ.png\"></figure><h4>Un peu de contexte</h4>\n<p>Globalement, les Français <a href=\"https://korii.slate.fr/et-caetera/impact-ai-ifop-etude-francais-et-ia-confiance-besoin-information\">sont méfiants</a> vis-à-vis de l’intelligence artificielle. Cette méfiance est renforcée par l’avènement du big data et la multiplication des données disponibles pour l’entrainement d’intelligences artificielles.</p>\n<p>En effet, les risques sont potentiellement nombreux : utilisation frauduleuse de données personnelles, présence de biais discriminatoires, … L’IA peut même devenir un outil de surveillance dans certains pays …</p>\n<p>Au sein de l’Union européenne, les pouvoirs publics sont conscients de ces risques et se saisissent du sujet, que ce soit au niveau européen avec la RGDP ou national (avec la CNIL en France).</p>\n<h4>Et pourquoi Shapash ?</h4>\n<p>Au sein de MAIF, nous avons évidemment un <strong>usage historique des données</strong>, pour proposer un conseil personnalisé à nos sociétaires, mais aussi pour maîtriser nos risques. Nous portons un intérêt tout particulier une utilisation éthique des données.</p>\n<blockquote>La transparence des algorithmes que nous développons est primordiale : c’est par cette transparence que l’IA peut renforcer la confiance !</blockquote>\n<p>Aussi, depuis quelques années, <strong>nous nous intéressons au domaine de l’intelligibilité des modèles de Data Science</strong>. Ce domaine évolue et plusieurs contributions open source paraissent régulièrement et sont souvent très pertinentes. Elles s’adressent essentiellement à un public de praticiens de la donnée.</p>\n<p>Avec <strong>Shapash</strong>, développé par des Data Scientists MAIF, <strong>nous avons souhaité proposer une solution qui s’adresse à tous</strong>, quel que soit son background data.</p>\n<p>Côté MAIF, <strong>Shapash</strong> nous permet:</p>\n<ul>\n<li>De <strong>faciliter le dialogue</strong> entre les Data Scientists et les acteurs non Data-techniciens de la mutuelle.</li>\n<li>Pour les Data Scientists, de comprendre plus facilement et plus rapidement comment fonctionnent les modèles qu’ils développent.</li>\n</ul>\n<p>Il nous parait aujourd’hui évident de proposer <strong>Shapash</strong> en Open Source !</p>\n<blockquote>Nous avons souhaité proposer une solution qui s’adresse à tous, quel que soit son background data.</blockquote>\n<h4>Que fait Shapash ?</h4>\n<p><strong>Shapash</strong> est une librairie Python qui vise à rendre le Machine Learning intelligible par le plus grand nombre.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/696/1*oaJTad5H3PZk5oUNrcoXag.gif\"><figcaption>Shapash Monitor Demo</figcaption></figure><p>Concrètement, il s’agit d’une surcouche à d’autres librairies d’intelligibilité (Shap, Lime) qui :</p>\n<ul>\n<li>Affiche des résultats intelligibles grâce à un wording et des visualisations simples, adaptés à un large public.</li>\n<li>Propose une interface qui facilite l’exploration des différentes features d’un modèle et permet la navigation entre explicabilité globale et locale. Cette interface est particulièrement utile pour animer des ateliers métiers et répondre en séance aux questions sur le fonctionnement du modèle de ML.</li>\n<li>Permet de résumer l’explicabilité locale pour la rendre utile dans un contexte opérationnel. Ce résumé est paramétrable pour s’adapter à différents cas d’usage, et peut être exporté.</li>\n<li>Est ouverte ! <strong>Shapash</strong> s’utilise pour des problématiques de Régression, Classification et se veut compatible avec une multitude de librairies de Machine Learning, d’encoding de features (encoding inverse), utilisable avec des contributions calculées par Lime, Shap, …</li>\n</ul>\n<p><strong>Shapash fonctionne pour tout type de cas d’usage. Il peut être utilisé dans le domaine de la santé, l’économie, marketing, …</strong></p>\n<p>N’hésitez pas à vous rendre sur le GitHub de <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a> : vous y trouverez une documentation plus exhaustive des fonctionnalités proposées par la librairie ainsi qu’une demo de la Web App Shapash Monitor pour un test rapide ! Et n’hésitez pas à mettre une étoile sur GitHub si vous aimez le projet !</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c216f9ddb2e9\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/shapash-une-nouvelle-solution-ossbymaif-pour-une-intelligence-artificielle-plus-transparente-c216f9ddb2e9\">Shapash : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus transparente</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Mélusine 2.0, en avant vers les modèles d’attention !",
    "author_id": "Tiphaine Fabre",
    "created_at": "2020-10-02 09:48:28",
    "id": "https://medium.com/p/219b03e101e1",
    "author_username": "Tiphaine Fabre",
    "author_name": "Tiphaine Fabre",
    "thumbnail": "https://cdn-images-1.medium.com/max/808/1*JYIvfU0aDATfp_gKpapb7g.png",
    "description": "\n<h3>Mélusine 2.0, en avant vers les modèles d’attention !</h3>\n<p>C’était il y a <a href=\"https://medium.com/oss-by-maif/melusine-une-nouvelle-brique-ossbymaif-pour-r%C3%A9-enchanter-les-emails-8e0f3b13e9f\">1 an et 6 mois</a> maintenant. Nous vous présentions <a href=\"https://github.com/MAIF/melusine\">Mélusine</a>, une solution Open source MAIF permettant la qualification des emails entrants grâce à des techniques avancées de traitement du langage, développée avec notre partenaire <a href=\"https://www.quantmetry.com/\">Quantmetry</a>. 6 mois plus tard, c’était au tour de notre <a href=\"https://medium.com/oss-by-maif/melusine-ethique-29664ad78f94\">nouvelle brique éthique</a> de venir compléter le projet. Aujourd’hui, nous sommes fiers de vous annoncer une mise à jour majeure de la solution puisque nous faisons évoluer les algorithmes d’intelligence artificielle au cœur même de Melusine !</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/808/1*JYIvfU0aDATfp_gKpapb7g.png\"></figure><p>Nous proposions jusqu’à présent des réseaux de neurones à convolution ou récurrents pour classifier les emails. En effet, ces derniers étaient les architectures à l’état de l’art du traitement automatique du langage. Mais les récents progrès dans le domaine nous ont poussé à éprouver les méthodes à attention. Introduits en 2014 par <a href=\"https://yoshuabengio.org/\">Yoshua Bengio</a> dans la publication scientifique « <a href=\"https://arxiv.org/abs/1409.0473\">Neural machine translation by jointly learning to align and translate</a>» pour une tâche de traduction automatique et généralisés par la suite pour diverses tâches de NLP, les modèles d’attention sont maintenant très utilisés voire même devenus incontournables. Il nous semblait donc essentiel d’intégrer ce type de modèles.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/824/1*7tTk9UBMrXdqzlezRZWx4A.png\"></figure><h3>Mais en quoi consistent ces modèles d’attention?</h3>\n<p>Ils présentent des différences structurelles avec les architectures évoquées. Les réseaux de convolutions vont progressivement abstraire le sens des mails par des opérations locales. Selon la profondeur du réseau, les couches cachées font émerger des motifs en fonction des mots d’un même voisinage. Pour les réseaux récurrents, les mots sont traités séquentiellement. Les couches cachées dépendent des états précédents, un peu comme si on lisait le texte de gauche à droite. Pour les méthodes d’attention, les couches cachées sont mises à jour simultanément et dépendent de l’ensemble des états précédents.</p>\n<p>En pratique, ces modèles d’attention prennent en entrée une séquence de mots et un vecteur de contexte et produisent en sortie une somme pondérée des vecteurs de la séquence. Les poids de pondérations sont calculés à partir du vecteur de contexte. Cette opération est facilement parallélisable, ce qui rend son implémentation extrêmement efficace !</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/748/1*Mah4XPhmtgSkevOTdFSJgQ.png\"></figure><p>Les opérations d’attentions sont généralement agrégées pour composer un réseau plus profond : les Transformers.</p>\n<h3>Les Transformers, c’est quoi ?</h3>\n<p>Cette architecture a pour origine le modèle <a href=\"https://arxiv.org/abs/1706.03762\">Transformer</a> présenté par Google AI en 2017. Le modèle est illustré ci-dessous et se compose d’un empilement de plusieurs couches similaires qui s’appuient en particulier sur le mécanisme d’attention. L’architecture inclue des couches d’encodeurs et de décodeurs qui permettent respectivement d’encoder ou de générer du texte. L’architecture peut ainsi être utilisée dans divers configurations :</p>\n<ul>\n<li>Encodeur-Encodeur : l’attention de chaque token de la séquence d’entrée se porte vers tous les autres tokens de cette séquence.</li>\n<li>Encodeur-Décodeur : l’attention du token à prédire est portée à tous les tokens de la séquence d’entrée.</li>\n<li>Décodeur-Décodeur : L’attention du token à prédire se porte sur les tokens qui le précèdent et les tokens déjà prédits se regardent entre eux.</li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/495/1*dU7M8BPsHEtUJhGV3KV2cA.png\"></figure><h3>Qu’est-ce que BERT a de plus ?</h3>\n<p>BERT (<a href=\"https://arxiv.org/abs/1810.04805\">Bidirectional Encoder Representations from Transformers</a>) utilise l’architecture Transformer. Il s’agit d’une architecture pour encoder le texte qui ne contient donc que des couches d’encodeurs. Une particularité du modèle est qu’il est <strong>pré-entrainé</strong>. Le modèle a été initialisé en apprenant à réaliser une tâche de manière auto-supervisée. Des mots sont volontairement masqués dans le jeu d’entrainement et BERT apprend à prédire ces mots masqués, on parle de « Masked Language Model ». Ce pré-entrainement s’effectue sur un grand volume de données couvrant divers sujets et donne à BERT une capacité à traiter des tâches spécialisées. Le modèle est ensuite <strong>fine-tuné</strong> : on l’entraine avec un faible taux d’apprentissage sur une tâche précise. Il surclasse de nombreux modèles spécialisés sur les tâches NLP de référence (<a href=\"https://rajpurkar.github.io/SQuAD-explorer/\">SQuAD</a>, <a href=\"https://gluebenchmark.com/\">GLUE</a>, BLEU)</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/766/1*Xf0Fpc8jdmtzCqLfBWyckg.png\"></figure><p>La mise à disposition, en 2019, de modèles BERT pré-entrainés en français a également pesé dans la balance. La majorité du flux email traité par la MAIF étant en français, l’usage des modèles <a href=\"https://arxiv.org/abs/1911.03894\">CamemBERT</a> et <a href=\"https://arxiv.org/abs/1912.05372\">FlauBERT</a> nous apportera, nous l’espérons, un apport conséquent dans l’optimisation du routage et l’amélioration du quotidien de nos conseillers MAIF. Comme illustré ci-dessous, nous avons adapté l’architecture pour inclure l’usage de méta données (pièces jointes, heure d’envoi …) en complément de Bert.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/709/1*l_dIM68tG_vrSaNrByDblA.png\"></figure><h3>À vous de jouer!</h3>\n<p>En attendant, <a href=\"https://github.com/MAIF/melusine\">Melusine 2.0</a> vous permet d’expérimenter par vous-même les <a href=\"https://huggingface.co/transformers/pretrained_models.html\">modèles disponibles</a> dans la librairie <a href=\"https://huggingface.co/transformers/pretrained_models.html\">Transformers</a> de la start-up Hugging Face ou les modèles CamemBERT ou FlauBERT que vous auriez déjà fine-tuné en local !</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*S2qEwANeCv9wkD4KTYkGlg.png\"></figure><p>Un <a href=\"https://github.com/MAIF/melusine/blob/master/tutorial/tutorial13_attention_models.ipynb\">tutoriel</a> vous accompagne sur l’utilisation des différentes architectures disponibles. <strong>Testez et n’hésitez pas à nous faire des retours ou à laisser une “star” sur </strong><a href=\"https://github.com/MAIF/melusine\"><strong>le GitHub</strong></a><strong> !</strong></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=219b03e101e1\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/m%C3%A9lusine-2-0-en-avant-vers-les-mod%C3%A8les-dattention-219b03e101e1\">Mélusine 2.0, en avant vers les modèles d’attention !</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Daikoku 1.0.0 is out !!",
    "author_id": "quentin aubert",
    "created_at": "2020-06-15 12:34:35",
    "id": "https://medium.com/p/d24348061967",
    "author_username": "quentin aubert",
    "author_name": "quentin aubert",
    "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*nxmbji8tMnuz--wPBzfEAA.png",
    "description": "\n<h3>Daikoku 1.0.0 is out !!</h3>\n<figure><img alt=\"Daikoku, the japanese god of wealth\" src=\"https://cdn-images-1.medium.com/max/1024/1*nxmbji8tMnuz--wPBzfEAA.png\"><figcaption>Daikoku, the japanese god of wealth</figcaption></figure><p>A new MAIF’s open source application is out. Like Batman has Robin, <a href=\"https://maif.github.io/otoroshi/\">Otoroshi</a> has <a href=\"https://maif.github.io/daikoku/\">Daikoku</a>.</p>\n<p>Daikoku is a developer portal for Otoroshi, written in scala and developed by the <a href=\"https://maif.github.io/\">MAIF OSS team</a>.</p>\n<p>Daikoku is a digital gateway into your API catalog.<br>It will help you to group and manage your APIs but also to present them to your collaborators, to your customers thanks to complete description page, usage documentation, technical documentation (OpenAPI, swagger), test console …</p>\n<p>It will streamline the process of subscribing to an api and get an API key from Otoroshi by leaving each user and team master of its own API keys without having to interact directly with Otoroshi. Let your collaborators and customers by allowing them to safely view their AIP keys or update their APIs as they want.</p>\n<p>With Daikoku, every user will be able to create teams, APIs, subscribe to APIs owned by other teams, try the APIs through the test console and consult their consumption or income. Thanks to multi-tenant, each instance of Daikoku can perfectly reflect your working environments, through an highly customizable UI.</p>\n<ul><li><strong>UI</strong></li></ul>\n<p>Daikoku is <strong>a user centric app with a gorgeous UI</strong>, which allows you and your collaborators or customers to subscribe to your APIs, but not only.<br>They can also manage teams, APIs (of course 😉 ), usage plans, documentation, swaggers, billing …</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-jEFhLVq7zxPAmkaGsWfNQ.png\"><figcaption>API plans</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CdRdvwbUQDvGA3_WJAGxSA.png\"><figcaption>API documentation</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*98C0jiyw0A5RAF8ytUIWYw.png\"><figcaption>API Reference</figcaption></figure><ul><li><strong>Multi-tenant</strong></li></ul>\n<p>Daikoku is multi-tenant with a <strong>unique configuration for every tenant</strong>.<br>Tenant can be private or public depending on your needs and internal workflows.</p>\n<ul><li><strong>Customization</strong></li></ul>\n<p><strong>Daikoku UI is highly customizable</strong> to reflect your tenant environment and your corporate theme. You can add new CSS, font family, custom footer, custom home page or JS (be careful though 🧐, with great power comes great responsibilities).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*a1hxrD6EV9U1_OcxyvbH_Q.png\"><figcaption>Branded home page</figcaption></figure><ul><li><strong>Authentication</strong></li></ul>\n<p>Authentication can be provided by Otoroshi using authentication modules but Daikoku itself provides local authentication, LDAP and OIDC connectors</p>\n<ul><li><strong>Initialization</strong></li></ul>\n<p>If you already using Otoroshi for a while, no problem, <strong>Daikoku can be initialized with an existing Otoroshi instance</strong>. APIs, teams and subscriptions will be created based on Otoroshi’s configuration.</p>\n<ul><li><strong>Admin API</strong></li></ul>\n<p>Even if Daikoku is user centric and therefore more UI oriented, it’s also API friendly. Daikoku offers admin APIs to to control your instances without a browser and maybe do <strong>some kind of automation based on your internal workflow</strong>.</p>\n<ul><li><strong>Integration</strong></li></ul>\n<p>An integration API is available to display a part of Daikoku anywhere you want (like on your corporate website)</p>\n<p>But we don’t stop there. We are planning a lot of exiting features for future releases like:</p>\n<ul>\n<li>Chat between customers and API admin</li>\n<li>Issues tracker</li>\n<li>Billing API</li>\n<li>versioning APIs</li>\n<li>and more…</li>\n</ul>\n<p>Come and try Daikoku at <a href=\"https://maif.github.io/daikoku/\">https://maif.github.io/daikoku/</a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d24348061967\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/daikoku-1-0-0-is-out-d24348061967\">Daikoku 1.0.0 is out !!</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Eurybia: MAIF releases a new open-source solution for quality IA models in production",
    "author_id": "Thomas Bouche",
    "created_at": "2022-05-05 15:06:49",
    "id": "https://medium.com/p/57bd0266a77e",
    "author_username": "Thomas Bouche",
    "author_name": "Thomas Bouche",
    "thumbnail": "https://cdn-images-1.medium.com/max/401/1*7zpHegFlmGm3P9DImJN_1A.jpeg",
    "description": "\n<p>MAIF, a French mutual insurance company (est. 1934), has been contributing to open source for a few years. Since 2019, we share our work in the field of artificial intelligence, our first release was <a href=\"https://github.com/MAIF/melusine\"><strong>Melusine</strong></a>, for french langage email processing and our second was <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a>, to make machine learning interpretable and understandable by everyone.</p>\n<p>We are now releasing <strong>Eurybia</strong>, a python library to ensure quality of machine learning model in production by detecting model drift. Eurybia also addresses challenges of <strong>industrialisation </strong>and<strong> maintainability </strong>of IA over time. Thus, it contributes for a better model monitoring, model auditing and more generally <strong>AI governance</strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/1*7zpHegFlmGm3P9DImJN_1A.jpeg\"><figcaption>Eurybia logo by MAIF</figcaption></figure><h3>Elements of context</h3>\n<p>More and more machine learning models are being deployed into production environments. A key step for deployment is to <strong>secure the data</strong> that will be used for the prediction model. This is crucial, notably when training and production data sources differ.</p>\n<p>While most models have been built from historical data and are static, data are usually dynamic, meaning that they change over time and so do the prediction capabilities. To have a controlled use of AI, it is important to <strong>detect these changes</strong> to determine if they are problematic, track performance over time, and consider re-training the model if necessary.</p>\n<h3>Why have we made Eurybia?</h3>\n<p>At MAIF, as an insurer, we’ve been using data for a long time, notably to simultaneously offer the best personalized advice to our customers and control insurance risks. Because of our history, as a committed mutual insurance company and because we believe that companies should be responsible for their use of data, we are particularly involved in AI governance.</p>\n<p>The visualization of the life cycle of a machine learning model can ease the understanding of Eurybia importance. During their life, ML models go through the following phases: Model learning, Model deployment, Model monitoring.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JfmSQHO-YML6egTUdSHifg.png\"><figcaption>life cycle machine learning model</figcaption></figure><p>To ensure that models perform in production as well as they did in training, it is important to verify that data are consistent and that<em> </em>features distributions are similar.</p>\n<p>We want to closely monitor our models in production, notably to detect as early as possible when models are likely to provide less suitable recommendations.</p>\n<p>At MAIF, we use Eurybia to:</p>\n<ul>\n<li>\n<strong>Secure model deployment</strong> by detecting any inherent data problems</li>\n<li>Help data analysts, data engineers and data scientists to<strong> collaborate</strong> for data validation before deploying a model into a production environment</li>\n<li>\n<strong>Make it easier and faster</strong> for MAIF’s data scientists to analyze data drift</li>\n<li>Know whether it is necessary to <strong>re-train</strong> the model</li>\n<li>Save <strong>drift monitoring</strong> reports for drift monitoring, for consultation following an e-mail alert or another specific need</li>\n</ul>\n<h3>What is Eurybia?</h3>\n<p>Eurybia is a Python library which aims to help detecting drift and validate data before putting a model in production (named deployed model).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*I8xUqyDEd287FWym0PDh_w.gif\"><figcaption>Eurybia Gif</figcaption></figure><p>Underneath, you’ll see a short description of elements which are referred to in this article.</p>\n<ul>\n<li>\n<strong>Data Validation</strong> : Validate that data used for production prediction are similar to training data or test data before deployment.</li>\n<li>\n<strong>Data drift</strong> : Evolution of the production data over time compared to training or test data before deployment.</li>\n<li>\n<strong>Model drift</strong> : Model performances’ evolution over time due to change in the target feature statistical properties (<strong>Concept drift</strong>), or due to change in data (<strong>Data drift</strong>).</li>\n</ul>\n<p>For technical definitions, we recommend to read the bibliography.</p>\n<p>For Data Validation and Data Drift, Eurybia works mainly with a <strong>binary classification model</strong> (named datadrift classifier) that tries to predict whether a sample belongs to the training/baseline dataset or to the production/current dataset.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*P-eHhByJHCjKUWiKY-lkVw.png\"><figcaption>How the datadrift classifier works</figcaption></figure><p>The <strong>explainability</strong> of this datadrift classifier provides higher scores to features that are important for drift. When combined with the initial deployed model features importances, this explainability reationalizes further analysis.</p>\n<p>Eurybia thus allows its users to :</p>\n<ul>\n<li>Get a quick overview of features that changed the most to <strong>prioritize study</strong> of drift</li>\n<li>\n<strong>Put into perspective</strong> the evolution of features with their importance for the deployed model. To study in priority drift on features with the most influence on the model</li>\n<li>Display each feature and its <strong>distribution</strong>\n</li>\n<li>Display the difference between the <strong>predicted probabilities distributions</strong> respectively based on the baseline dataset and the production dataset</li>\n<li>Have a performance metric for data drift and <strong>track it over time</strong>\n</li>\n</ul>\n<p>Eurybia also has additional features that allow to :</p>\n<ul>\n<li>Analyze <strong>data consistency</strong> by checking if features are the same between baseline and production dataset, as well as features modalities</li>\n<li>Detect model drift by <strong>displaying model performance over time</strong> (a section we would like to develop in future Eurybia releases)</li>\n<li>\n<strong>Save a dynamic report</strong> that allows collaboration between colleagues, drift analysis, and for audit purposes</li>\n</ul>\n<p>Eurybia can be used for all kinds of use cases and domains : health, business, marketing, …</p>\n<p>Please visit <a href=\"https://github.com/MAIF/shapash\"><strong>Eurybia’s GitHub</strong></a> : there, you will find more exhaustive documentation of the library’s features as well as a <a href=\"https://eurybia.readthedocs.io/en/latest/report.html\"><strong>demo</strong></a> of the dynamic report for a quick test! Please do not hesitate to give us a star on GitHub if you like the project!</p>\n<p>Maif open source several libraries and not only data science libraries, you can visit them <a href=\"https://maif.github.io/\"><strong>here</strong></a>.</p>\n<h3>Further readings</h3>\n<p>We have quickly introduced the notion of drift. If you wish to learn more about drift, I recommend the following resources :</p>\n<ul>\n<li>Drift classification and retraining: <a href=\"https://towardsdatascience.com/model-drift-in-machine-learning-models-8f7e7413b563\">https://towardsdatascience.com/model-drift-in-machine-learning-models-8f7e7413b563</a>\n</li>\n<li>Concept drift characterization: <a href=\"https://arxiv.org/pdf/1511.03816.pdf\">https://arxiv.org/pdf/1511.03816.pdf</a>\n</li>\n<li>Mathematical view for different types of drifts : <a href=\"https://medium.com/data-from-the-trenches/a-primer-on-data-drift-18789ef252a6\">https://medium.com/data-from-the-trenches/a-primer-on-data-drift-18789ef252a6</a>\n</li>\n<li>Data drift detection: <a href=\"https://arxiv.org/pdf/2012.09258.pdf\">https://arxiv.org/pdf/2012.09258.pdf</a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=57bd0266a77e\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/eurybia-maif-releases-a-new-open-source-solution-for-quality-ia-models-in-production-57bd0266a77e\">Eurybia: MAIF releases a new open-source solution for quality IA models in production</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  },
  {
    "text": "Eurybia : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus maîtrisée",
    "author_id": "Thomas Bouche",
    "created_at": "2022-05-05 15:05:07",
    "id": "https://medium.com/p/843e651a2ced",
    "author_username": "Thomas Bouche",
    "author_name": "Thomas Bouche",
    "thumbnail": "https://cdn-images-1.medium.com/max/401/1*7zpHegFlmGm3P9DImJN_1A.jpeg",
    "description": "\n<h3>Eurybia : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus maîtrisée</h3>\n<p>La MAIF contribue à l’open source depuis plusieurs années et, depuis 2019, nous partageons nos travaux dans le domaine de l’intelligence artificielle. Nous avons libéré <a href=\"https://github.com/MAIF/melusine\"><strong>Melusine</strong></a>, pour le traitement des emails en langue française, puis <a href=\"https://github.com/MAIF/shapash\"><strong>Shapash</strong></a>, pour rendre l’intelligence artificielle plus transparente et compréhensible par tous.</p>\n<p><strong>Aujourd’hui, nous vous présentons </strong><a href=\"https://github.com/MAIF/eurybia\"><strong>Eurybia</strong></a><strong> !</strong></p>\n<p>Cette librairie Python garantit la qualité des modèles de machine learning en production (c’est à dire une fois qu’il sont déployés au sein de l’entreprise) en détectant leur dérive et répond ainsi aux défis de l’<strong>industrialisation</strong> et de la <strong>maintenabilité</strong> de l’IA dans le temps. Elle contribue à une meilleure surveillance des modèles, à leur audit et plus généralement à la <strong>gouvernance de l’IA</strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/1*7zpHegFlmGm3P9DImJN_1A.jpeg\"><figcaption>Eurybia par MAIF</figcaption></figure><h3>Les enjeux pour une IA de qualité : sécuriser et de maintenir les modèles de machine learning</h3>\n<p>En effet, de plus en plus de modèles de machine learning sont déployés en production. Une étape clé du déploiement consiste à <strong>sécuriser la qualité des données</strong> qui seront utilisées pour la prédiction ou recommandation poussée par le modèle de machine learning. Cette étape est cruciale, notamment lorsque les sources des données d’apprentissage et de production diffèrent.</p>\n<p>Alors que la plupart des modèles sont construits à partir de données historiques qui sont statiques, les données de production sont généralement dynamiques : elles évoluent dans le temps, et donc les prédictions/recommandations qui s’appuient sur ces données évoluent aussi. Pour avoir une utilisation contrôlée de l’IA, il est important de <strong>détecter ces écarts</strong> afin de déterminer s’ils posent problème, suivre les performances dans le temps, et envisager de ré-entraîner le modèle si nécessaire.</p>\n<h3>Eurybia, un outil qui répond aujourd’hui à nos besoins …</h3>\n<p>Au sein de la MAIF, nous avons évidemment un <strong>usage historique des données</strong>, pour proposer un conseil personnalisé à nos sociétaires, mais aussi pour maîtriser nos risques. De par notre histoire, en tant que mutuelle engagée et parce que nous pensons que les entreprises doivent être responsables de leur utilisation des données, nous sommes particulièrement impliqués dans la gouvernance de l’IA.</p>\n<p>Un modèle de <em>machine learning </em>passe par les phases suivantes au fil de son cycle de vie : Apprentissage du modèle, Déploiement du modèle, Monitoring du modèle — <em>voir schéma ci-dessous.</em></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JfmSQHO-YML6egTUdSHifg.png\"><figcaption>Cycle de vie d’un modèle de machine learning</figcaption></figure><p>Pour s’assurer que les modèles fonctionnent en production aussi bien qu’à l’apprentissage, il est important de vérifier que les données sont cohérentes et que les distributions des variables du modèle sont similaires.</p>\n<p>Nous souhaitons suivre de près nos modèles en production, notamment pour détecter au plus tôt lorsque les modèles sont susceptibles de fournir des recommandations moins adaptées.</p>\n<p><strong>A la MAIF, nous utilisons Eurybia pour :</strong></p>\n<ul>\n<li>\n<strong>Sécuriser la mise en production</strong> de modèle en détectant tout problème inhérent aux données</li>\n<li>Aider les data analysts, data engineers et data scientists à <strong>collaborer</strong> pour valider les données avant de déployer un modèle en production.</li>\n<li>\n<strong>Faciliter et accélérer</strong> l’analyse de la dérive des données par les data scientists de la MAIF.</li>\n<li>Savoir s’il est nécessaire de <strong>ré-entraîner</strong> le modèle</li>\n<li>\n<strong>Sauvegarder des rapports</strong> pour le suivi de la dérive, pour une consultation suite à une alerte e-mail ou un autre besoin spécifique.</li>\n</ul>\n<h3>…et que nous libérons en open-source afin de contribuer à une IA plus maîtrisée</h3>\n<p>Eurybia est une librairie Python qui a pour but d’aider à détecter les dérives et à valider les données avant de mettre un modèle en production.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*I8xUqyDEd287FWym0PDh_w.gif\"><figcaption>Démo du rapport Eurybia</figcaption></figure><p>Dans cet article, nous ferons référence à ces différents termes :</p>\n<ul>\n<li>\n<strong>Validation des données</strong> : Valider que les données utilisées pour la prédiction en production sont similaires aux données d‘apprentissage avant le déploiement.</li>\n<li>\n<strong>Dérive des données</strong> : Évolution des données de production dans le temps par rapport aux données d’apprentissage.</li>\n<li>\n<strong>Dérive du modèle</strong> : Évolution des performances du modèle dans le temps, en raison d’un changement des propriétés statistiques de la variable cible (<strong>dérive de concept</strong>), ou en raison d’un changement des données (<strong>dérive des données</strong>).</li>\n</ul>\n<p><em>Pour les définitions techniques, nous vous recommandons de lire la bibliographie.</em></p>\n<p>Pour la validation des données et la dérive des données, Eurybia fonctionne principalement grâce à un <strong>modèle de classification binaire</strong> (appelé <em>datadrift classifier</em>). Ce modèle tente de prédire si un individu appartient aux données d’entraînement ou aux données en production, c’est à dire de déterminer dans quel mesure ces deux jeux de données sont différents. Si ce <em>datadrift classifier</em> a des performances élevés, alors la dérive est importante.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GN1jh-TpRHZG0KW1Mz0qAw.png\"><figcaption>Fonctionnement principal d’Eurybia</figcaption></figure><p>L’<strong>explicabilité</strong> du <em>datadrift classifier</em> fournit des résultats plus élevés aux variables qui sont importantes pour la dérive. Combinée à l’importance des variables du modèle déployé, cette explicabilité permet de prioriser l’analyse.</p>\n<p><strong>Eurybia permet ainsi :</strong></p>\n<ul>\n<li>D’avoir un aperçu rapide des variables qui ont le plus changé pour <strong>prioriser l’étude</strong> de la dérive.</li>\n<li>De <strong>mettre en perspective</strong> l’évolution des variables avec leur importance pour le modèle déployé. Et donc d’étudier en priorité la dérive des variables ayant le plus d’influence sur le modèle.</li>\n<li>D’afficher les <strong>distributions</strong> variable par variable</li>\n<li>D’afficher la différence de distribution entre les <strong>probabilités de la prédiction</strong> du modèle sur le jeu de données d’apprentissage et le jeu de données en production.</li>\n<li>D’avoir des métriques qui indiquent le niveau de dérive des données et les <strong>suivre dans le temps</strong>.</li>\n</ul>\n<p><strong>Eurybia dispose également de fonctionnalités supplémentaires qui permettent de :</strong></p>\n<ul>\n<li>Analyser la <strong>cohérence des données</strong> en vérifiant si les variables sont les mêmes entre le jeu de données d’apprentissage et le jeu de données de production, ainsi que les modalités des variables.</li>\n<li>Détecter les dérives du modèle en <strong>affichant les performances du modèle</strong> dans le temps. (Pour bien répondre à la problématique du modèle drift, nous souhaitons développer le concept drift dans les prochaines versions d’Eurybia).</li>\n<li>\n<strong>Sauvegarder un rapport dynamique</strong> qui facilite la collaboration entre collègues, et qui permet d’avoir un livrable à des fins d’audit.</li>\n</ul>\n<p>Eurybia fonctionne pour tout type de cas d’usage. Il peut être utilisé dans le domaine de la santé, l’économie, marketing, …</p>\n<p>N’hésitez pas à vous rendre sur le GitHub de <a href=\"https://github.com/MAIF/eurybia\"><strong>Eurybia</strong></a> : vous y trouverez une documentation exhaustive des fonctionnalités proposées par la librairie ainsi qu’une <a href=\"https://eurybia.readthedocs.io/en/latest/report.html\"><strong>demo</strong></a> du rapport Eurybia pour un test rapide ! Et n’hésitez pas à mettre une étoile sur GitHub si vous aimez le projet !</p>\n<p>La MAIF contribue à plusieurs librairies open source, et pas que des librairies de data science. Vous pouvez consultez le catalogue <a href=\"https://maif.github.io/\"><strong>ici</strong></a>.</p>\n<h3>Lectures complémentaires</h3>\n<p>Nous avons rapidement introduit la notion de dérive. Si vous souhaitez en savoir plus sur la dérive, je vous recommande les ressources suivantes :</p>\n<ul>\n<li>Drift classification and retraining: <a href=\"https://towardsdatascience.com/model-drift-in-machine-learning-models-8f7e7413b563\">https://towardsdatascience.com/model-drift-in-machine-learning-models-8f7e7413b563</a>\n</li>\n<li>Concept drift characterization: <a href=\"https://arxiv.org/pdf/1511.03816.pdf\">https://arxiv.org/pdf/1511.03816.pdf</a>\n</li>\n<li>Mathematical view for different types of drifts : <a href=\"https://medium.com/data-from-the-trenches/a-primer-on-data-drift-18789ef252a6\">https://medium.com/data-from-the-trenches/a-primer-on-data-drift-18789ef252a6</a>\n</li>\n<li>Data drift detection: <a href=\"https://arxiv.org/pdf/2012.09258.pdf\">https://arxiv.org/pdf/2012.09258.pdf</a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=843e651a2ced\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/oss-by-maif/eurybia-une-nouvelle-solution-ossbymaif-pour-une-intelligence-artificielle-plus-ma%C3%AEtris%C3%A9e-843e651a2ced\">Eurybia : Une nouvelle solution #OSSByMAIF pour une Intelligence Artificielle plus maîtrisée</a> was originally published in <a href=\"https://medium.com/oss-by-maif\">OSS by MAIF</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
  }
]